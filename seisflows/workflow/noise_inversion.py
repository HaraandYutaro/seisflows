#!/usr/bin/env python3
"""
Ambient Noise Adjoint Tomography workflow based on Wang et al. (see ref. below)
where Synthetic Greens functions (SGF) are generated by simulating point forces
in the Z, N and E directions. SGFs are rotated to the R and T components
to get ZZ, RR and TT SGFs that can be compared to data.

.. note:: EGF Data Location

    Empirical Greens Function data (noise cross correlations) must be placed
    in specific directory structures, and are searched for under the following
    locations:

        ZZ kernel: `path_data`/{source_name}/ZZ/*
        RR kernel: `path_data`/{source_name}/RR/*
        TT kernel: `path_data`/{source_name}/TT/*

.. note:: Kernel Naming

    The kernel naming convention used in this workflow follows from Ref. 1.
    Two letter names (e.g., AB) where first letter (A) represents input force
    direction, and second letter (B) represents the component of the recorded
    wavefield. E.g., ZZ represents an upward (+Z) force recorded on Z component.
    In ambient noise, the common EGFs are ZZ, TT and RR. Cross-component EGFs
    (e.g., ZT) are also possible, but not currently supported. Please open
    a GitHub issue if you would like to see these supported.

.. note:: References

    1. "Three‚Äêdimensional sensitivity kernels for multicomponent empirical
        Green's functions from ambient noise: Methodology and application to
        Adjoint tomography."
        Journal of Geophysical Research: Solid Earth 124.6 (2019): 5794-5810.

.. warning::

    This workflow class makes a lot of assumptions about file naming and 
    path structure defined in other modules that is verging on hard coding. May
    warrant a re-write in the future.  I've tried to mark all the file/dir.
    naming assumptions with a '!!!'
"""
import os

from concurrent.futures import ProcessPoolExecutor, wait
from glob import glob
from obspy import Stream

from seisflows import logger
from seisflows.tools import unix, msg
from seisflows.tools.noise import rotate_ne_trace_to_rt, rotate_rt_adjsrc_to_ne
from seisflows.preprocess.default import read, write
from seisflows.workflow.inversion import Inversion


class NoiseInversion(Inversion):
    """
    Noise Inversion Workflow
    ------------------------
    Run forward and adjoint solvers to produce Synthetic Greens Functions (SGF)
    based on unidirectional forces which are meant to represent virtual
    sources of uniform noise distributions. SGFs are compared to Empirical
    Greens Functions (EGF) for iterative model updates.

    .. note:: simulation requirements per source station

        - 'ZZ' kernel requires 1 forward (Z) and 1 adjoint (Z) simulation
        - 'TT or RR' kernel requires 2 forward (N + E) and 2 adjoint (N_? + E_?)
           simulations (where ? = R or T)
        - 'TT,RR' kernels can share their 2 forward simulations (N + E) but
          require 4 separate adjoint simulations (N_T + E_T + N_R + E_R)
        - 'ZZ,TT or ZZ,RR' requires 3 forward (Z + N + E) and 3 adjoint
        - 'ZZ,TT,RR' requires 3 forward (Z + N + E) and 5 adjoint
           (Z + N_T + E_T + N_R + E_R)

    Parameters
    ----------
    :type kernels: str
    :param kernels: comma-separated list of kernels to generate w.r.t available
        EGF data. Corresponding data must be available. Available options are:

        - 'ZZ': vertical component force recorded on vertical component.
          Represents Rayleigh wave energy
        - 'TT': transverse copmonent force recorded on transverse component.
          Represents Love wave energy
        - 'RR': radial component force recorded on radial component.
          Represents Rayleigh wave energy

        Example inputs would be 'ZZ' or 'ZZ,TT' or 'ZZ,TT,RR'. Case insensitive

    Paths
    -----

    ***
    """
    __doc__ = Inversion.__doc__ + __doc__

    def __init__(self, kernels="ZZ", **kwargs):
        """
        Initialization of the Noise Inversion Workflow module
        """
        super().__init__(**kwargs)

        self.kernels = kernels.upper()

        # Internal variables control behavior of spawned jobs. These should not
        # be set by the User, they are set by main processing functions here.
        self._force = None  # direction of input force for fwd/adj simulation
        self._cmpnt = None  # component of output synthetics/adjsrcs used

    def check(self):
        """
        Additional checks for the Noise Inversion Workflow to ensure the
        required modules and parameters are set
        """
        super().check()

        assert("3D" in self._modules.solver.__class__.__name__), (
            f"Noise Inversion workflow requires solver module 'specfem3d' or " 
            f"'specfem3d_globe'"
        )

        assert(self.data_case == "data"), \
            f"Noise Inversion workflow must have `data_case` == 'data'"

        assert(self._modules.solver.source_prefix == "FORCESOLUTION"), (
            f"Noise Inversion workflow requires solver `source_prefix` to be " 
            f"'FORCESOLUTION'"
        )

        assert(self._modules.preprocess.syn_data_format == "ASCII"), (
            f"Noise Inversion workflow requires solver `syn_data_format` to be " 
            f"'ASCII'"
        )

        acceptable_kernels = {"ZZ", "TT", "RR"}
        assert(set(self.kernels.split(",")).issubset(acceptable_kernels)), \
            f"`kernels` must be a subset of {acceptable_kernels}"

        # TODO: Check whether data exists for all sources/master stations

        # TODO: Check that solver parameter ROTATE_SEISMOGRAMS_RTZ == False (?)

    @property
    def task_list(self):
        """
        USER-DEFINED TASK LIST. This property defines a list of class methods
        that take NO INPUT and have NO RETURN STATEMENTS. This defines your
        linear workflow, i.e., these tasks are to be run in order from start to
        finish to complete a workflow.

        This excludes 'check' (which is run during 'import_seisflows') and
        'setup' which should be run separately

        .. note::

            For workflows that require an iterative approach (e.g. inversion),
            this task list will be looped over, so ensure that any setup and
            teardown tasks (run once per workflow, not once per iteration) are
            not included.

        :rtype: list
        :return: list of methods to call in order during a workflow
        """
        # Standard inversion tasks
        return [self.generate_event_kernels,
                self.postprocess_event_kernels,
                self.evaluate_gradient_from_kernels,
                self.initialize_line_search,
                self.perform_line_search,
                self.finalize_iteration
                ]

    def trace_path(self, tag, comp=None):
        """
        Convenience path function that returns the full path for storing
        intermediate waveform files for a given component. 
        These generally adhere to how the `solver` module names directories. 
        
        Required because this workflow will do a lot of pre-rotation waveform 
        storage, so we use this function as the once-and-for-all definition for 
        the paths

        .. note ::

            Must be run by system.run() so that solvers are assigned individual
            task ids and working directories

        :type tag: str or None
        :param tag: sub directory tag, e.g., 'syn' to store synthetic waveforms 
            and 'adj' to store adjoint sources.
        :type comp: str or None
        :param comp: optional component used to tag the sub directory
        :rtype: str
        :return: full path to solver scratch traces directory to save waveforms
        """
        if comp is not None:
            tag = f"{tag}_{comp}".lower()
        return os.path.join(self.solver.cwd, "traces", tag)

    def generate_event_kernels(self):
        """
        Main processing function for Noise Inversion workflow, which manipulates
        the standard Inversion workflow functions `evaluate_initial_misfit` and
        `run_adjoint_simulations`.

        Uses User-defined parameter `kernels` to determine workflow:

        - ZZ: Generates Synthetic Greens Functions (SGF) for the ZZ component by
            running forward simulations for each master station using a +Z
            component force, and then running an adjoint simulation to generate
            kernels.
        - TT/RR: Generate Synthetic Greens Functions (SGF) for the TT and/or RR
            component(s) following processing steps laid out in
            Wang et al. (2019) and outlined below:

        .. note:: TT/RR Workflow Steps:

            FORWARD SIMULATIONS
            1. Run E component forward simulation, save ZNE traces & fwd arrays
            2. Run N component forward simulations, save ZNE traces & fwd arrays
            3. Rotate N and E component SGF to R and T components based on
               source-receiver azimuth
            4. Calculate RR and TT adjoint sources (u_rr, u_tt) w.r.t EGF data

            GENERATE TT KERNELS
            5a. Rotate u_tt to N and E (u_ee, u_en, u_ne, u_nn)
            6a. Run ET adjoint simulation (injecting u_ee, u_en) for K_ET
            7a. Run NT adjoint simulation (injecting u_ne, u_nn) for K_NT
            8a. Sum T kernels, K_ET + K_NT = K_TT

            GENERATE RR KERNELS
            5b. Rotate u_rr to N and E (u_ee, u_en, u_ne, u_nn)
            6b. Run ER adjoint simulation (injecting u_ee, u_en) for K_ER
            7b. Run NR adjoint simulation (injecting u_ne, u_nn) for K_NR
            8b. Sum R kernels, K_ER + K_NR = K_RR

            9. Sum kernels K = K_RR + K_TT
        """
        # Set up a template file name, will be used for preprocessing residuals
        # Looks like e.g., 'residuals_NN_SSS_1_0_ZZ.txt'
        residuals_fid = f"residuals_{{src}}_{self.iteration}_0_{{tag}}.txt"
        save_residuals = os.path.join(self.path.eval_grad, residuals_fid)

        if "ZZ" in self.kernels:
            logger.info(msg.mnr("EVALUATING ZZ KERNELS FOR INITIAL MODEL"))

            # Internal tracking parameters used to name sub-directories, save
            # files and dictate how simulatuions are run
            self._force = "Z"
            self._cmpnt = "Z"

            # Run the forward solver to generate SGFs and adjoint sources.
            # Save the residual files but do not sum, will sum all at very end
            self.evaluate_initial_misfit(
                save_residuals=save_residuals.format(src="{src}",
                                                     tag=self._force),
                sum_residuals=False
            )

            # Run the adjoint solver to generate kernels for ZZ
            self.run_adjoint_simulations()

        if "RR" in self.kernels or "TT" in self.kernels:
            logger.info(msg.mnr("EVALUATING RR/TT KERNELS FOR INITIAL MODEL"))

            # Run the forward solver to generate E? and N? SGFs and adj sources
            # Order of simulations matters here! E must be first as preprocess
            # will hold until N simulations are run. The result of this step
            # are R and T adjoint sources
            for force in ["E", "N"]:
                self._force = force
                logger.info(f"running misfit evaluation for: '{self._force}'")
                self.evaluate_initial_misfit(
                    save_residuals=save_residuals.format(src="{src}", tag="RT"),
                    sum_residuals=False
                )

            # Run adjoint solver for each kernel RR and TT (if requested) by
            # running two adjoint simulations (E and N) per kernel.
            for cmpnt in ["T", "R"]:
                # Skip over if User did not request
                if cmpnt not in self.kernels:  # e.g., if 'R' in 'RR,TT'
                    continue

                # Set internal kernel variable which will let all spawned jobs
                # know which set of adjoint sources are required for their sim
                logger.info(f"running generating kernel for component: {cmpnt}")
                self._cmpnt = cmpnt  # T or R

                # We require two adjoint simulations/kernel to recover gradient
                for force in ["E", "N"]:
                    self._force = force
                    logger.info(f"running adjoint simulation for "
                                f"'{self._force}{self._cmpnt}'")
                    self.run_adjoint_simulations()

                # Unset internal variables to avoid any confusion in future runs
                self._cmpnt = None
                self._force = None

        # Sum all the misfit values together to create misfit value `f_new`.
        # This is the same process that occurs at the end of
        # Inversion.evaluate_initial_misfit but slightly more general
        residuals_files = glob(save_residuals.format(src="*", tag="*"))
        total_misfit = self.sum_residuals(residuals_files)
        self.optimize.save_vector(name="f_new", m=total_misfit)
        logger.info(f"total misfit `f_new` ({self.evaluation}) = "
                    f"{total_misfit:.2E}")

    def prepare_data_for_solver(self, **kwargs):
        """
        Function Override of `workflow.forward.prepare_data_for_solver()` 
        This will be run from within the `evaluate_initial_misfit` function.

        .. note ::

            Must be run by system.run() so that solvers are assigned individual
            task ids and working directories

        .. note::

            Changes the location of expected observed data, and removes any data
            previously stored within the `solver/traces/obs/` directory to avoid
            data conflict during workflow

            Data are searched for under the following locations:

                ZZ kernel: `path_data`/{source_name}/ZZ/*
                RR kernel: `path_data`/{source_name}/RR/*
                TT kernel: `path_data`/{source_name}/TT/*
        """
        # Define where the obs data is stored
        dst = self.trace_path("obs")

        # Since we need to run multiple preprocessing runs, we remove any
        # existing data that might have been placed here previously to avoid
        # data conflicts
        unix.rm(glob(os.path.join(dst, "*")))

        # Used for wildcard path naming ('ZZ,RR,TT' -> 'RT')
        wildcard = "".join([_[0] for _ in self.kernels.split(",") if _ != "ZZ"])

        # Generating a wildcard string that will be used to copy in data
        dir_ = {"Z": "ZZ",
                "N": f"[{wildcard}][{wildcard}]",  # [RT][RT] -> both RR and TT
                "E": f"[{wildcard}][{wildcard}]"
                }[self._force]

        # Access the specific 'obs' data path and feed that to the original fx.
        # !!! Assuming the data directory structure
        src = os.path.join(self.path.data, self.solver.source_name, dir_, "*")

        # Use Forward workflow machinery to copy in required EGF data
        super().prepare_data_for_solver(_src=src)

    def evaluate_objective_function(self, save_residuals=False, components=None,
                                    **kwargs):
        """
        Function Override of `workflow.inversion.evaluate_objective_function` to
        get expected adjoint sources for each kernel.

        Calls Preprocessing module to calculate misfit (f) and adjoint sources.

        ZZ kernel creation requires little modification and generally follows
        the original workflow function.

        RR and TT kernels require modification:
        - output synthetics are rotated from N/E to R/T, to match EGF data for
          misfit quantification
        - R and T adjoint sources are rotated back to N and E for
          adjoint simulations

        .. note::

            Must be run by system.run() so that solvers are assigned individual
            task ids/ working directories.
        """
        # Z component force behaves like a normal workflow, except that we only
        # create adjoint sources for the Z component, E and N will be zeros
        if self._force == "Z":
            super().evaluate_objective_function(save_residuals=save_residuals,
                                                components=["Z"])
        # Run E and N misfit quantification
        else:
            # Order of forward simulations matters! E simulations must be first
            if self._force == "E":
                logger.info("waiting for additional N component forward "
                            "simulation before proceeding with R/T "
                            "preprocessing")
                return

            # This will generate RR and TT synthetics in `traces/syn` with
            # synthetics generated using `traces/syn_e` and `traces/syn_n`
            self.rotate_ne_traces_to_rt()

            # Run preprocessing with rotated synthetics for horizontal cmpnts,
            # generate adjoint sources for R and T components
            super().evaluate_objective_function(save_residuals=save_residuals,
                                                components=["T", "R"]
                                                )
            # Re-rotate T and R adjoint sources to N and E components for 
            # adjoint simulations. Only rotate what is required for adj sim.
            for choice in ["T", "R"]:
                if choice in self.kernels:
                    self.rotate_rt_adjsrcs_to_ne(choice=choice)

    def rotate_ne_traces_to_rt(self):
        """
        Rotates N and E component waveforms generated by N and E force sources
        into R and T component, generated by R and T force sources.

        .. note::

            Must be run by system.run() so that solvers are assigned individual
            task ids/ working directories.
        """
        logger.info("rotating N and E synthetics to RR and TT components")

        # Gather waveform files from previous simulations and sort so that they
        # are technically in the same order. Assuming directory structure here.
        fids_nn = sorted(glob(os.path.join(self.trace_path(tag="syn", comp="n"),
                                           self.solver.data_wildcard(comp="N")))
                         )
        fids_ne = sorted(glob(os.path.join(self.trace_path(tag="syn", comp="n"),
                                           self.solver.data_wildcard(comp="E")))
                         )
        fids_en = sorted(glob(os.path.join(self.trace_path(tag="syn", comp="e"),
                                           self.solver.data_wildcard(comp="N")))
                         )
        fids_ee = sorted(glob(os.path.join(self.trace_path(tag="syn", comp="e"),
                                           self.solver.data_wildcard(comp="E")))
                         )

        # Double check that we have found files and that they match
        assert(len(fids_nn) != 0), f"No synthetic traces found for rotation"

        # Ensure that we actually found files and that they all match
        assert (len(fids_nn) == len(fids_ne) == len(fids_en) == len(fids_ee)), \
            f"number of synthetic waveforms does not match for all comps"

        # Rotate NE streams to RT in parallel
        with ProcessPoolExecutor(max_workers=unix.nproc()) as executor:
            futures = [
                executor.submit(self._rotate_ne_trace_to_rt_single,
                                f_nn, f_ne, f_en, f_ee)
                for f_nn, f_ne, f_en, f_ee in zip(fids_nn, fids_ne,
                                                  fids_en, fids_ee)
                ]
        # Simply wait until this task is completed because they are file writing
        wait(futures)

    def _rotate_ne_trace_to_rt_single(self, f_nn, f_ne, f_en, f_ee):
        """
        Parallalizable function to be called in scucession to rotate NE traces
        to RT for use in misfit quantification

        :type f_nn: str
        :param f_nn: path to the NN synthetic waveform (N force, N component)
        :type f_ne: str
        :param f_ne: path to the NE synthetic waveform (N force, E component)
        :type f_en: str
        :param f_en: path to the EN synthetic waveform (E force, N component)
        :type f_nn: str
        :param f_nn: path to the NN synthetic waveform (N force, N component)
        """
        src_name = self.solver.source_name

        # Figure out station and file naming from the parts of the file ID
        net, sta, cha, *ext = os.path.basename(f_nn).split(".")
        ext = ".".join(ext)  # e.g., SEM3DGLOBE ['sem', 'ascii'] -> sem.ascii
        rcv_name = f"{net}_{sta}"

        # Collect azimuth angles from lookup table computed in setup
        theta = self.preprocess.srcrcv_stats[src_name][rcv_name].theta
        theta_p = self.preprocess.srcrcv_stats[src_name][rcv_name].theta_p

        # Read in the N/E synthetic waveforms that need to be rotated
        # Assuming that each Stream only has one Trace in it
        tr_nn = read(f_nn, data_format=self.solver.syn_data_format)[0]
        tr_ne = read(f_ne, data_format=self.solver.syn_data_format)[0]
        tr_ee = read(f_ee, data_format=self.solver.syn_data_format)[0]
        tr_en = read(f_en, data_format=self.solver.syn_data_format)[0]

        # Apply rotation to get RR and TT synthetics
        tr_rr, tr_tt = rotate_ne_trace_to_rt(tr_ee=tr_ee, tr_ne=tr_ne,
                                             tr_en=tr_en, tr_nn=tr_nn,
                                             theta=theta, theta_p=theta_p)

        # Write synthetics back to the main synthetic trace directory for
        # subsequent misfit quantification
        if "TT" in self.kernels:
            # scratch/solver/{source_name}/traces/syn/NN.SSS.?XT.sem?*
            fid_t = os.path.join(self.solver.cwd, "traces", "syn",
                                 f"{net}.{sta}.{cha[:2]}T.{ext}")
            write(st=Stream(tr_tt), fid=fid_t,
                  data_format=self.solver.syn_data_format)
        if "RR" in self.kernels:
            # scratch/solver/{source_name}/traces/syn/NN.SSS.?XR.sem?*
            fid_r = os.path.join(self.solver.cwd, "traces", "syn",
                                 f"{net}.{sta}.{cha[:2]}R.{ext}")
            write(st=Stream(tr_rr), fid=fid_r,
                  data_format=self.solver.syn_data_format)

    def rotate_rt_adjsrcs_to_ne(self, choice):
        """
        Rotates N and E synthetics generated by N and E forward simulations to
        RR and TT component using the (back)azimuth between two stations. Saves
        the resulting waveforms to `solver/{source_name}/traces/syn/*`

        Necessary because the ANAT simulations are performed for N and E forces
        and components, but EGF data is usually given in R and T components to
        isolate Rayleigh and Love waves.

        :type choice: str
        :param choice: define the input component, 'R' or 'T' for the incoming
            adjoint source. Also gathered from `fid` but this is used to keep
            things safer and more explicit.
        """
        assert(choice in ["R", "T"]), f"`choice` must be in 'R', 'T'"

        # Define the list of file ids and paths required for rotation.
        # !!! Hard coding the file naming schema of SPECFEM adjoint sources
        _fid_wc = os.path.join(self.trace_path(tag="adj"), f"*.?X{choice}.adj")
        fids = sorted(glob(_fid_wc))

        # Few checks before providing this to parallel processing
        assert fids, f"no adjoint sources found for path: {_fid_wc}"
        logger.info(f"rotating {len(fids)} {choice} component adjoint sources")

        # Generate holding directories for rotated adjoint sources which will
        # be queried during each adjoint simulation
        for comp in [f"e{choice.lower()}", f"n{choice.lower()}"]:
            if not os.path.exists(self.trace_path(tag="adj", comp=comp)):
                # e.g., path/to/traces/adj_et
                unix.mkdir(self.trace_path(tag="adj", comp=comp))

        # Rotate NE streams to RT in parallel
        with ProcessPoolExecutor(max_workers=unix.nproc()) as executor:
            futures = [
                executor.submit(self._rotate_rt_adjsrc_to_ne_single, fid)
                for fid in fids
                ]
        # Simply wait until this task is completed with file writing
        wait(futures)

    def _rotate_rt_adjsrc_to_ne_single(self, fid):
        """
        Parallellizable function to rotate N and E trace to R and T based on
        a single source station and receiver station pair and their
        respective azimuth v# e.g., path/to/traces/adj_et
        """
        src_name = self.solver.source_name

        # Define pertinent information about files and output names
        net, sta, cha, *ext = os.path.basename(fid).split(".")
        comp = cha[-1].lower()
        ext = ".".join(ext)  # ['semd', 'ascii'] -> 'semd.ascii.'
        rcv_name = f"{net}_{sta}"

        # Collect azimuth angles from lookup table computed in preprocess setup
        theta = self.preprocess.srcrcv_stats[src_name][rcv_name].theta
        theta_p = self.preprocess.srcrcv_stats[src_name][rcv_name].theta_p

        # Read in the N/E synthetic waveforms that need to be rotated
        # First letter represents the force direction, second is component
        # e.g., ne -> north force recorded on east component
        tr_in = read(fid, data_format=self.preprocess.syn_data_format)[0]

        # Rotate the given adjoint source to get four adjoint sources which
        # are required for the N and E component adjoint simulations
        tr_ee, tr_ne, tr_en, tr_nn = rotate_rt_adjsrc_to_ne(tr_in=tr_in,
                                                            theta=theta,
                                                            theta_p=theta_p)

        # EE and EN are used for the E forcesolution adjoint simulation
        fid_ee = os.path.join(self.trace_path(tag="adj", comp=f"e{comp}"),
                              f"{net}.{sta}.{cha[:2]}E.{ext}")
        fid_en = os.path.join(self.trace_path(tag="adj", comp=f"e{comp}"),
                              f"{net}.{sta}.{cha[:2]}N.{ext}")
        fid_ne = os.path.join(self.trace_path(tag="adj", comp=f"n{comp}"),
                              f"{net}.{sta}.{cha[:2]}E.{ext}")
        fid_nn = os.path.join(self.trace_path(tag="adj", comp=f"n{comp}"),
                              f"{net}.{sta}.{cha[:2]}N.{ext}")

        # Write out all the rotated adjoint sources to the correct data
        # directory, so they are discoverable by the adjoint simulations
        write(st=Stream(tr_ee), fid=fid_ee,
              data_format=self.preprocess.syn_data_format)
        write(st=Stream(tr_en), fid=fid_en,
              data_format=self.preprocess.syn_data_format)
        write(st=Stream(tr_ne), fid=fid_ne,
              data_format=self.preprocess.syn_data_format)
        write(st=Stream(tr_nn), fid=fid_nn,
              data_format=self.preprocess.syn_data_format)

    def run_forward_simulations(self, path_model, **kwargs):
        """
        Function Override of `workflow.forward.run_forward_simulation` 

        Performs curated FORCESOLUTION file manipulation and output file 
        redirects to get synthetic waveform data in the correct location for
        future preprocessing steps. Able to handle Z, N and E forces required 
        for ZZ, TT and RR kernel generation.

        .. note::

            Must be run by system.run() so that solvers are assigned individual
            task ids/ working directories.

        :type path_model: str
        :param path_model: path to SPECFEM model files used to run the forwarsd
            simulations. Files will be copied to each individual solver
            directory.
        :raises AssertionError: if internal variable `_force` is not set by
            the calling function
        """
        # Internal variable check
        assert(self._force is not None), (
            f"`run_forward_simulation` requires that the internal attribute " 
            f"`_force` is set prior to running forward simulations"
        )

        # Edit the force vector based on the internal value for chosen kernel
        kernel_vals, save_traces = None, None
        if self._force == "Z":
            kernel_vals = ["0.d0", "0.d0", "1.d0"]  # format: [E, N, Z]
            # ZZ SGFs are just saved straight to the 'syn' directory
            save_traces = self.trace_path(tag="syn")
        else:
            if self._force == "N":
                kernel_vals = ["0.d0", "1.d0", "0.d0"]  # format: [E, N, Z]
            elif self._force == "E":
                kernel_vals = ["1.d0", "0.d0", "0.d0"]  # format: [E, N, Z]
            # e.g., solver/{source_name}/traces/syn_e
            save_traces = self.trace_path(tag="syn", comp=self._force)

        # Clear out synthetics from previous evaluations to avoid file conflict
        unix.rm(os.path.join(save_traces, "*"))
        unix.mkdir(save_traces)

        # Set FORCESOLUTION (3D/3D_GLOBE) to ensure correct force for kernel
        self.solver.set_parameters(keys=["component dir vect source E",
                                         "component dir vect source N",
                                         "component dir vect source Z_UP"],
                                   vals=kernel_vals, file="DATA/FORCESOLUTION",
                                   delim=":")

        # Exporting traces to disk for permanent saving. Ensure that the force
        # tag is set so that subsequent trace exports don't overwrite existing
        if self.export_traces:
            # e.g., output/{source}/syn_Z_1_0/*
            export_traces = os.path.join(
                self.path.output, self.solver.source_name,
                f"syn_{self._force}_{self.evaluation}"
            )
        else:
            export_traces = False

        super().run_forward_simulations(path_model, save_traces=save_traces,
                                        export_traces=export_traces, **kwargs
                                        )

    def _run_adjoint_simulation_single(self, save_kernels=None, 
                                       export_kernels=None, **kwargs):
        """
        Function Override of `workflow.migration._run_adjoint_simulation_single`

        1) Creates necessary empty adjoint sources, e.g., ZZ kernel only 
           requires 'Z' component adjoint sources, and 'N' and 'E' MUST be 0
        2) For N and E (TT and RR kernels) adjoint simulations, symlinks collect
           adjoint sources to be discoverable by SPECFEM. Note that for 
           horizontal components, four sets of adjoint sources are available.

        .. note::

            Must be run by system.run() so that solvers are assigned
            individual task ids/working directories.
        """
        # Internal variable check
        assert(self._force is not None), (
            f"`run_adjoint_simulations` requires that the internal attribute " 
            f"`_force` is set prior to running forward simulations"
        )
        assert(self._cmpnt is not None), (
            f"`run_adjoint_simulations` requires that the internal attribute " 
            f"`_cmpnt` is set prior to running forward simulations"
        )
        # Kernel subdirectory should be one of: ZZ, NT, ET, NR, ER
        subdir = f"{self._force}{self._cmpnt}"

        # Redirect paths to where we save and export kernels to avoid overwrites
        if save_kernels is None:
            save_kernels = os.path.join(self.path.eval_grad, "kernels",
                                        self.solver.source_name, subdir)
        if export_kernels is None and self.export_kernels:
            export_kernels = os.path.join(self.path.output, "kernels",
                                          self.solver.source_name, subdir)
        else:
            export_kernels = False

        # Run adjoint simulations for each kernel
        if self._force == "Z":
            self._generate_empty_adjsrcs(components=["E", "N"])
            
            super()._run_adjoint_simulation_single(save_kernels, export_kernels)
        elif self._force in ["E", "N"]:
            # Remove any existing adjoint sources from directory 
            unix.rm(self.trace_path(tag="adj"))
            unix.mkdir(self.trace_path(tag="adj"))

            # Generate empty Z components because we only have E and N component
            self._generate_empty_adjsrcs(components=["Z"])

            # Symlink the correct set of adjoint sources to the 'adj' directory
            # `adj_dir` is something like 'adj_nt'
            adj_dir = self.trace_path(
                tag="adj", comp=f"{self._force.lower()}{self._cmpnt.lower()}"
            )
            for src in glob(os.path.join(adj_dir, "*")):
                unix.ln(src, self.trace_path("adj"))

            super()._run_adjoint_simulation_single(save_kernels, export_kernels)

    def _generate_empty_adjsrcs(self, components):
        """
        Internal NoiseInversion function used to generate empty (zero amplitude) 
        adjoint sources for every station and given `component`. Uses the Solver 
        and Preprocess modules to get after file naming and trace 
        characteristics.

        This function is required because the original Inversion method for 
        generating empty adjoint sources is insuffficient for the file structure
        that gets craeted here

        .. warning::

            !!! This entire function makes assumptions about file naming
            structure for SPECFEM generated synthetics that may be too rigid/
            hardcoded.

        .. note::

            Must be run by system.run() so that solvers are assigned
            individual task ids/working directories.

        :type components: list of str
        :param components: components to generate empty adjoint sources for.
            e.g., ['E', 'N'] will generate E and N component adjoint sources.
            Note that any files matching the output adjoint source file name
            will be removed so ensure that there is no actual adjoint source
            data in this file.
        """
        # Grab a dummy synthetic trace to use for time series structure
        st = read(fid=self.solver.data_filenames("syn")[0],
                  data_format=self.solver.syn_data_format)
        st[0].data *= 0  # zero out the amplitude for empty adjoint source

        # Get list of synthetic traces which require a corresponding adj source
        # and rename them so that they follow the expected SPECFEM format
        adj_fids = [
                self.solver.rename_as_adjoint_source(os.path.basename(f))
                for f in self.solver.data_filenames("syn")
                ]

        for fid in adj_fids:
            # !!! Making assumptions about the filenaming structure here
            channel = fid.split(".")[2]  # NN.SSS.CCc.adj
            # Write out adjoint sources for all requested components
            for component in components:
                channel_out = channel[:2] + component  # e.g., MXZ -> MXR
                # !!! May be an issue if station name is the same as channel
                fid_out = fid.replace(channel, channel_out)
                adjpath = os.path.join(self.trace_path("adj"), fid_out)
                # Do not overwrite existing adjoint sources
                if not os.path.exists(adjpath):
                    write(st=st, fid=adjpath,
                          data_format=self.preprocess.syn_data_format
                          )

    def postprocess_event_kernels(self):
        """
        Function Override of `workflow.migration.postprocess_event_kernels`

        Combines multiple individual kernels, K, for each source.
        That is `K_event = K_ZZ + K_TT + K_RR`, where (K_TT = K_ET + K_NT and 
        K_RR = K_ER + K_NR). Uses the original function machinery to do the
        final kernel summation (K_misfit = sum(K_event)) and postprocessing
        (smoothing, masking, etc.)

        .. warning::

            Assumes the subdirectory structure of kernels for path `eval_grad`
        """
        # If only ZZ kernels, then we don't need to do any prior kernel summing.
        # Simply reorganize directory structures so that the original function
        # can find the required files
        if self.kernels == "ZZ":
            # $ mv kernels/src/ZZ/* -> kernels/src
            for srcname in self.solver.source_names:
                dst = os.path.join(self.path.eval_grad, "kernels", srcname)
                src = glob(os.path.join(dst, "ZZ", "*"))

                unix.mv(src=src, dst=dst)

            super().postprocess_event_kernels()

            # Return to avoid accessing code below which is only required if any
            # horizontal components are involved
            return

        # RR and TT kernels require running SPECFEM executable `xcombine_sem`
        # so we need to define a function which can be fed to 'system.run()'
        def generate_event_kernels(**kwargs):
            """
            Combine horizontal (TT=ET+NT; RR=ER+NR) kernels and then sum
            all individual kernel contributions (ZZ+RR+TT) to generate the final
            event kernel for each source.

            .. note::

                Must be run by system.run(single=True) so that the operation
                has access to the compute node for the kernel combination
            """
            # Parameters are constant and static for this whole process
            parameters = [f"{par}_kernel" for par in self.solver._parameters] 

            # We need to combine the N? and E? kernels for each source by itself
            for src in self.solver.source_names:
                # Subdirectory containing kernels for a given source
                # !!! Assuming the dir. structure defined by postprocess module
                src_path = os.path.join(self.path.eval_grad, "kernels", src)

                # This will bring in all available kernels from: ER, NR, ET, NT
                for kernel in ["RR", "TT"]:
                    if kernel not in self.kernels:
                        continue
                    input_paths = [os.path.join(src_path, f"E{kernel[0]}"),
                                   os.path.join(src_path, f"N{kernel[0]}")]

                # Sum in ZZ kernels to the final event kernel if available
                if "ZZ" in self.kernels:
                    input_paths.append(os.path.join(src_path, "ZZ"))

                # We drop the event kernel directly into the source 
                # subdirectory to match the expected input of the original fx.
                output_path = os.path.join(self.path.eval_grad, "kernels", src)

                # Use the solver function to combine kernels
                self.solver.combine(input_paths, output_path, parameters)
        
        # Run above function on system to get access to compute node
        self.system.run([generate_event_kernels], single=True)

        # Now the original function takes over and combines event kernels into
        # a misfit kernel, and applies smoothing, masking, etc.
        super().postprocess_event_kernels()

    def _evaluate_line_search_misfit(self):
        """
        Function Overwrite of `workflow.inversion._evaluate_line_search_misfit`
        Called inside `workflow.inversion.perform_line_search`
        
        Line search requires running forward simulations multiple times to 
        generate the correct synthetics, as well as some synthetic rotation
        if TT or RR included in kernels

        TODO clean out the traces/syn directory because it is causing false
            misfit calculations for 'evaluate_objective_function'

        .. warning::

            Each call of this function will save residuals but these will be 
            ignored and the final residual file will only be created once all 
            forward simulations are run
        """
        iteration = self.iteration
        step_count = self.optimize.step_count

        # Set up a template file name, will be used for preprocessing residuals
        # Same as in `generate_kernels` (!!! Should this be made a parameter?)
        resi_rid = f"residuals_{{src}}_{iteration}_{step_count}_{{tag}}.txt"
        save_residuals = os.path.join(self.path.eval_func, resi_rid)

        # Pre-set functions and parameters for system.run calls
        run_list = [self.prepare_data_for_solver,
                    self.run_forward_simulations,
                    self.evaluate_objective_function
                    ]
        path_model = os.path.join(self.path.eval_func, "model")

        # Determine which forward simulations we will need to run
        forces = []
        if "ZZ" in self.kernels:
            forces.append("Z")
        if ("RR" in self.kernels) or ("TT" in self.kernels):
            # Order of simulations matters here! E must be first as
            # preprocessing will hold until N simulations are run.
            forces.append("E")
            forces.append("N")

        # Run forward simulations and misfit calculation for each required force
        for force in forces:
            self._force = force
            logger.info(f"running misfit evaluation for: '{self._force}'")
            # Z residuals will be saved tag Z, N/E residuals saved tag RT
            tag = {"Z": "Z", "N": "RT", "E": "RT"}[self._force]
            self.system.run(
                run_list, path_model=path_model,
                save_residuals=save_residuals.format(src="{src}", tag=tag)
            )
       
        # Sum misfit from all forward simulations
        residuals_files = glob(save_residuals.format(src="*", tag="*"))
        assert residuals_files, (
                f"No residuals files found for Iteration {iteration} and "
                f"step count {step_count}. Please check preprocessing"
                )
        total_misfit = self.sum_residuals(residuals_files)

        logger.debug(f"misfit for trial model (f_try) == {total_misfit:.2E}")
        self.optimize.save_vector(name="f_try", m=total_misfit)


