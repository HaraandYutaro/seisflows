:py:mod:`seisflows3.system.slurm`
=================================

.. py:module:: seisflows3.system.slurm

.. autoapi-nested-parse::

   The Simmple Linux Utility for Resource Management (SLURM) is a commonly used
   workload manager on many high performance computers / clusters. The Slurm
   system class provides generalized utilites for interacting with Slurm systems.

   Useful commands for figuring out system-specific required parameters
       $ sinfo --Node --long  # Determine the cores-per-node for partitions

   .. note::
       The main development system for SeisFlows3 used SLURM. Therefore the other
       system supers will not be up to date until access to those systems are
       granted. This rosetta stone, for converting from SLURM to other workload
       management tools will be useful: https://slurm.schedmd.com/rosetta.pdf



Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   seisflows3.system.slurm.Slurm



Functions
~~~~~~~~~

.. autoapisummary::

   seisflows3.system.slurm.job_id_list
   seisflows3.system.slurm.job_array_status
   seisflows3.system.slurm.check_job_state



Attributes
~~~~~~~~~~

.. autoapisummary::

   seisflows3.system.slurm.PAR
   seisflows3.system.slurm.PATH


.. py:data:: PAR
   

   

.. py:data:: PATH
   

   

.. py:class:: Slurm

   Bases: :py:obj:`custom_import`\ (\ :py:obj:`'system'`\ , :py:obj:`'cluster'`\ )

   Generalized interface for submitting jobs to and interfacing with a SLURM
   workload management system.

   .. py:attribute:: logger
      

      

   .. py:method:: required(self)
      :property:

      A hard definition of paths and parameters required by this class,
      alongside their necessity for the class and their string explanations.


   .. py:method:: submit(self, submit_call=None)

      Submits workflow as a single process master job

      :type workflow: module
      :param workflow:
      :type submit_call: str
      :param submit_call: subclasses (e.g., specific SLURM cluster subclasses)
          can overload the sbatch command line input by setting
          submit_call. If set to None, default submit_call will be set here.


   .. py:method:: run(self, classname, method, single=False, run_call=None, **kwargs)

      Runs task multiple times in embarrassingly parallel fasion on a SLURM
      cluster. Executes classname.method(*args, **kwargs) `NTASK` times,
      each time on `NPROC` CPU cores

      .. note::
          The actual CLI call structure looks something like this
          $ sbatch --args scripts/run OUTPUT class method environs

      :type classname: str
      :param classname: the class to run
      :type method: str
      :param method: the method from the given `classname` to run
      :type single: bool
      :param single: run a single-process, non-parallel task, such as
          smoothing the gradient, which only needs to be run by once.
          This will change how the job array and the number of tasks is
          defined, such that the job is submitted as a single-core job to
          the system.
      :type run_call: str
      :param run_call: subclasses (e.g., specific SLURM cluster subclasses)
          can overload the sbatch command line input by setting
          run_call. If set to None, default run_call will be set here.


   .. py:method:: taskid(self)

      Provides a unique identifier for each running task

      :rtype: int
      :return: identifier for a given task



.. py:function:: job_id_list(stdout, single)

   Parses job id list from sbatch standard output. Stdout typically looks
   like: 'Submitted batch job 441636', but if submitting jobs cross-cluster
   (e.g., like on Maui), stdout might be:
   'Submitted batch job 441636 on cluster Maui'

   .. note::
       In order to find the job number, we just scan each word in stdout
       until we find the number, ASSUMING that there is only one number in
       the string

   TODO Should failing to return job_id break in reasonable way?

   The output job arrays will look something like:
   [44163_0, 44163_1, ..., 44163_PAR.NTASK]

   :type stdout: str
   :param stdout: the text response from running 'sbatch' on SLURM, which
       should be returned by subprocess.run(stdout=PIPE)
   :type single: bool
   :param single: if running a single process job, returns a list of length
       1 with a single job id, else returns a list of length PAR.NTASK
       for all arrayed jobs
   :rtype: list
   :return: a list of array jobs that should be currently running


.. py:function:: job_array_status(job_ids)

   Determines current status of job or job array

   :type job_ids: list
   :param job_ids: list of SLURM job id numbers to check completion of
       Will not return unless all jobs have completed
   :rtype is_done: bool
   :return is_done: True if all jobs in the array have been completed
   :rtype states: list
   :return states: list of states returned from sacct


.. py:function:: check_job_state(job_id)

   Queries completion status of a single job by running:
       $ sacct -nL -o jobid,state -j {job_id}

       # Example outputs from this sacct command
       # JOB_ID    STATUS
       441630_0  PENDING  # array job will have the array number
       441630    COMPLETED  # if --array=0-0, jobs will not have suffix
       441628.batch    COMPLETED  # we don't want to check these

   Available job states: https://slurm.schedmd.com/sacct.html

   .. note::
       -L flag in sacct queries all available clusters, not just the
       cluster that ran the `sacct` call
       -X supress the .batch and .extern jobname

   :type job: str
   :param job: job id to query


